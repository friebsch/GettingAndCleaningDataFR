?Devices
windows()
pdf(file ="Fabian")
plot(x, y)
dev.off()
getwd()
qt(0.025, df = 21)
qt(0.025, df = 22)
pt(2.30, df = 21)
2 * pt(2.30, df = 21, lower.tail = FALSE)
2 * pt(2.24, df = 21, lower.tail = FALSE)
pf(21.735, 3, 791, lower.tail = FALSE)
2 * pt(0.5, df = 17, lower.tail = FALSE)
load(url("http://bit.ly/dasi_nc"))
str(dc)
str(nc)
summary(nc)
is.na(nc$gained)
sum(nc$gained == na)
sum(is.na(nc$gained))
gained_clean = na.omit(nc$gained)
n = length(gained_clean)
boot_means = rep(NA, 100)
for(i in 1:100){
boot_sample = sample(gained_clean, n, replace = TRUE)
boot_means[i] = mean(boot_sample)
}
hit(boot_means)
hist(boot_means)
source("http://bit.ly/dasi_inference")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.9, est = "mean",
boot_method = "perc")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "mean",
boot_method = "perc")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "mean",
boot_method = "se")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "median",
boot_method = "se")
inference(nc$fage, type = "ci", method = "simulation", conflevel = 0.95, est = "mean",
boot_method = "se")
plot(nc$habit, nc$weight)
by(nc$weight, nc$habit, mean)
with(nc$weight, nc$habit, mean)
by(nc$weight, nc$habit, mean)
by(nc$weight, nc$habit, length)
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ht", null = 0,
alternative = "twosided", method = "theoretical")
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ht", null = 0,
alternative = "twosided", method = "theoretical", order = c("smoker","nonsmoker"))
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ci", null = 0,
alternative = "twosided", method = "theoretical", order = c("smoker","nonsmoker"))
summary(nc)
by(nc$mature, nc$age, mean)
by(nc$mature, nc$mage, mean)
by(nc$mature, nc$mage)
by(nc$mature, nc$mage, lenght)
by(nc$mature, nc$mage, length)
tail(nc$mature)
summary(nc)
load(url("http://bit.ly/dasi_gss_ws_cl"))
inference(y = gss$wordsum, x = gss$class, est = "mean", type = "ht",
alternative = "greater", method = "theoretical")
?dnorm
?qnorm
n.
load(url("http://www.openintro.org/stat/data/mlb11.RData"))
plot(mlb11$at_bats, mlb11$runs)
cor(mlb11$runs, mlb11$at_bats)
plot(mlb11$runs, mlb11$at_bats)
plot_ss(x = mlb11$at_bats, y = mlb11$runs)
plot_ss(x = mlb11$at_bats, y = mlb11$runs, showSquares = TRUE)
m1 <- lm(runs ~
at_bats, data = mlb11)
m1
summary(m1)
m1 <- lm(runs ~
homeruns, data = mlb11)
summary(m1)
plot(mlb11$runs ~
mlb11$at_bats)
abline(m1)
m1 <- lm(runs ~
at_bats, data = mlb11)
abline(m1)
plot(m1$residuals ~
mlb11$at_bats)
abline(h = 0, lty = 3)
hist(m1$residuals)
qqnorm(m1$residuals)
qqline(m1$residuals)
plot(mlb11$runs ~
mlb11$hits)
plot(mlb11$runs ~
mlb11$wings)
plot(mlb11$runs ~
mlb11$wins)
plot(mlb11$runs ~
mlb11$batting_average)
str(mlb11)
plot(mlb11$runs ~
mlb11$bat_avg)
plot(mlb11$runs ~
mlb11$at_bats)
plot(mlb11$runs ~
mlb11$hits)
plot(mlb11$runs ~
mlb11$bat_avg)
m1 <- lm(runs ~
hits, data = mlb11)
summary(m1)
m1 <- lm(runs ~
bat_ave, data = mlb11)
m1 <- lm(runs ~
bat_avg, data = mlb11)
summary(m1)
m1 <- lm(runs ~
new_obs, data = mlb11)
summary(m1)
m1 <- lm(runs ~
new_slug, data = mlb11)
summary(m1)
m1 <- lm(runs ~
new_onbase, data = mlb11)
summary(m1)
library(DAAG)
install.packages(DAAG)
load(url("http://www.openintro.org/stat/data/evals.RData"))
summary(evals)
plot(evals$score ~
evals$bty_avg)
?jitter
m_bty <- lm(score ~ rank, data = evals)
abline(m_bty)
m_bty <- lm(rank ~ score, data = evals)
m_bty <- lm(score ~ rank, data = evals)
summary (m_btly)
summary (m_bty)
m_bty <- lm(score ~ bty_avg, data = evals)
summary (m_bty)
abline(m_bty)
hist(m_bty4$residuals)
hist(m_bty$residuals)
plot(m_bty$residuals)
plot(evals$bty_avg ~
evals$bty_f1lower)
cor(evals$bty_avg, evals$bty_f1lower)
plot(evals[,13:19])
m_bty_gen <- lm(score ~
bty_avg + gender, data = evals)
summary(m_bty_gen)
multiLines(m_bty_gen)
m_bty_gen <- lm(score ~
bty_avg + rank, data = evals)
summary(m_bty_gen)
m_full <- lm(score ~
rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m_full)
1+1
install.packages(c("aplpack", "DBI", "devtools", "jsonlite", "MASS", "minqa", "Rcpp", "testthat"))
6^2+2
38^2
install.packages("knitr")
install.packages("rmarkdown")
x <- [10,   2,   6,   12,   14,   15,   15,   24,   15,   25,   3,   12]
x <- [10,2,6,12,14,15,15,24,15,25,3,12]
x <- (10,2,6,12,14,15,15,24,15,25,3,12)
x <- c(10,2,6,12,14,15,15,24,15,25,3,12)
sd(x)
iqr(x)
IQR(x)
quantile(x, 1/4)
quantile(x, 2/4)
quantile(x, 3/4)
quantile(x, 4/4)
mean(x)
median(x)
range(x)
hist(x)
quantile(x, 1/4)
con = url("http://biostat.jhsph.edu/~jleek/contact.html ")
htmlCode = readLines(con)
close(con)
htmlCode
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
x <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
sum(x[,4])
setwd("d:/Benutzer/Fabian/Dropbox/Uni/Fortbildung/Coursera/Coursera Data Since Specialisation/Coursera - Getting and Cleaning Data/GettingAndCleaningDataFR/")
library("data.table")
library("reshape2")
#load libraries
library("data.table")
library("reshape2")
path <- getwd()
path
#load libraries
library("data.table")
library("reshape2")
#set the actualPath Variable to work with
actualPath <- getwd()
actualPath
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(actualPath)) {
dir.create(actualPath)
}
download.file(url, file.path(actualPath, f))
timeDownloaded <- Sys.time
timeDownloaded
#load libraries
library("data.table")
library("reshape2")
#set the actualPath Variable to work with
actualPath <- getwd()
actualPath
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(actualPath)) {
dir.create(actualPath)
}
download.file(url, file.path(actualPath, f))
timeDownloaded <- Sys.time()
timeDownloaded
#load libraries
library("data.table")
library("reshape2")
#set the actualPath Variable to work with
actualPath <- getwd()
actualPath
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(actualPath)) {
dir.create(actualPath)
}
#download.file(url, file.path(actualPath, f))
#timeDownloaded <- Sys.time()
timeDownloaded
pathIn <- file.path(actualPath, "UCI HAR Dataset")
list.files(pathIn, recursive = TRUE)
#load libraries
library("data.table")
library("reshape2")
#set the actualPath Variable to work with
actualPath <- getwd()
actualPath
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(actualPath)) {
dir.create(actualPath)
}
#download.file(url, file.path(actualPath, f)) and set time. (in my case: "2014-11-22 17:56:59 CET")
#timeDownloaded <- Sys.time()
timeDownloaded
dataPath <- file.path(actualPath, "UCI HAR Dataset")
list.files(dataPath, recursive = TRUE)
#read files
dtSubjectTrain <- fread(file.path(dataPath, "train", "subject_train.txt"))
dtSubjectTest <- fread(file.path(dataPath, "test", "subject_test.txt"))
dtActivityTrain <- fread(file.path(dataPath, "train", "Y_train.txt"))
dtActivityTest <- fread(file.path(dataPath, "test", "Y_test.txt"))
#load libraries
library("data.table")
library("reshape2")
#set the actualPath Variable to work with
actualPath <- getwd()
actualPath
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(actualPath)) {
dir.create(actualPath)
}
#download.file(url, file.path(actualPath, f)) and set time. (in my case: "2014-11-22 17:56:59 CET")
#timeDownloaded <- Sys.time()
timeDownloaded
dataPath <- file.path(actualPath, "UCI HAR Dataset")
list.files(dataPath, recursive = TRUE)
#read files
subjectTrain <- fread(file.path(dataPath, "train", "subject_train.txt"))
subjectTest <- fread(file.path(dataPath, "test", "subject_test.txt"))
yTrain <- fread(file.path(dataPath, "train", "Y_train.txt"))
yTest <- fread(file.path(dataPath, "test", "Y_test.txt"))
xTrain <- fread(file.path(dataPath, "train", "X_train.txt"))
xTest <- fread(file.path(dataPath, "test", "X_test.txt"))
#merge Files
dtSubject <- rbind(subjectTrain, subjectTest)
setnames(dtSubject, "V1", "subject")
dtActivity <- rbind(yTrain, yTest)
setnames(dtActivity, "V1", "activityNum")
dt <- rbind(xTrain, xTest)
dtSubject <- cbind(dtSubject, dtActivity)
dt <- cbind(dtSubject, dt)
setkey(dt, subject, activityNum)
dtFeatures <- fread(file.path(dataPath, "features.txt"))
setnames(dtFeatures, names(dtFeatures), c("featureNum", "featureName"))
dtFeatures <- dtFeatures[grepl("mean\\(\\)|std\\(\\)", featureName)]
dtFeatures$featureCode <- dtFeatures[, paste0("V", featureNum)]
head(dtFeatures)
#load libraries
library("data.table")
library("reshape2")
#set the actualPath Variable to work with
actualPath <- getwd()
actualPath
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(actualPath)) {
dir.create(actualPath)
}
#download.file(url, file.path(actualPath, f)) and set time. (in my case: "2014-11-22 17:56:59 CET")
#timeDownloaded <- Sys.time()
timeDownloaded
dataPath <- file.path(actualPath, "UCI HAR Dataset")
list.files(dataPath, recursive = TRUE)
#read files
subjectTrain <- fread(file.path(dataPath, "train", "subject_train.txt"))
subjectTest <- fread(file.path(dataPath, "test", "subject_test.txt"))
yTrain <- fread(file.path(dataPath, "train", "Y_train.txt"))
yTest <- fread(file.path(dataPath, "test", "Y_test.txt"))
fileToDataTable <- function(f) {
df <- read.table(f)
dt <- data.table(df)
}
xTrain <- fileToDataTable(file.path(pathIn, "train", "X_train.txt"))
xTest <- fileToDataTable(file.path(pathIn, "test", "X_test.txt"))
#merge Files
dtSubject <- rbind(subjectTrain, subjectTest)
setnames(dtSubject, "V1", "subject")
dtActivity <- rbind(yTrain, yTest)
setnames(dtActivity, "V1", "activityNum")
dt <- rbind(xTrain, xTest)
dtSubject <- cbind(dtSubject, dtActivity)
dt <- cbind(dtSubject, dt)
setkey(dt, subject, activityNum)
dtFeatures <- fread(file.path(dataPath, "features.txt"))
setnames(dtFeatures, names(dtFeatures), c("featureNum", "featureName"))
dtFeatures <- dtFeatures[grepl("mean\\(\\)|std\\(\\)", featureName)]
dtFeatures$featureCode <- dtFeatures[, paste0("V", featureNum)]
head(dtFeatures)
#load libraries
library("data.table")
library("reshape2")
#set the actualPath Variable to work with
actualPath <- getwd()
actualPath
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(actualPath)) {
dir.create(actualPath)
}
#download.file(url, file.path(actualPath, f)) and set time. (in my case: "2014-11-22 17:56:59 CET")
#timeDownloaded <- Sys.time()
timeDownloaded
dataPath <- file.path(actualPath, "UCI HAR Dataset")
list.files(dataPath, recursive = TRUE)
#read files
subjectTrain <- fread(file.path(dataPath, "train", "subject_train.txt"))
subjectTest <- fread(file.path(dataPath, "test", "subject_test.txt"))
yTrain <- fread(file.path(dataPath, "train", "Y_train.txt"))
yTest <- fread(file.path(dataPath, "test", "Y_test.txt"))
fileToDataTable <- function(f) {
df <- read.table(f)
dt <- data.table(df)
}
xTrain <- fileToDataTable(file.path(pathIn, "train", "X_train.txt"))
xTest <- fileToDataTable(file.path(pathIn, "test", "X_test.txt"))
#merge Files
dtSubject <- rbind(subjectTrain, subjectTest)
setnames(dtSubject, "V1", "subject")
dtActivity <- rbind(yTrain, yTest)
setnames(dtActivity, "V1", "activityNum")
dt <- rbind(xTrain, xTest)
dtSubject <- cbind(dtSubject, dtActivity)
dt <- cbind(dtSubject, dt)
setkey(dt, subject, activityNum)
dtFeatures <- fread(file.path(dataPath, "features.txt"))
setnames(dtFeatures, names(dtFeatures), c("featureNum", "featureName"))
dtFeatures <- dtFeatures[grepl("mean\\(\\)|std\\(\\)", featureName)]
dtFeatures$featureCode <- dtFeatures[, paste0("V", featureNum)]
#subsetting
select <- c(key(dt), dtFeatures$featureCode)
dt <- dt[, select, with = FALSE]
#get activity names
activityNames <- fread(file.path(dataPath, "activity_labels.txt"))
setnames(activityNames, names(activityNames), c("activityNum", "activityName"))
#merge lables and data and set key
dt <- merge(dt, activityNames, by = "activityNum", all.x = TRUE)
setkey(dt, subject, activityNum, activityName)
dt <- data.table(melt(dt, key(dt), variable.name = "featureCode"))
dt <- merge(dt, dtFeatures[, list(featureNum, featureCode, featureName)], by = "featureCode", all.x = TRUE)
dt$activity <- factor(dt$activityName)
dt$feature <- factor(dt$featureName)
grepthis <- function(regex) {
grepl(regex, dt$feature)
}
## Features with 2 categories
n <- 2
y <- matrix(seq(1, n), nrow = n)
x <- matrix(c(grepthis("^t"), grepthis("^f")), ncol = nrow(y))
dt$featDomain <- factor(x %*% y, labels = c("Time", "Freq"))
x <- matrix(c(grepthis("Acc"), grepthis("Gyro")), ncol = nrow(y))
dt$featInstrument <- factor(x %*% y, labels = c("Accelerometer", "Gyroscope"))
x <- matrix(c(grepthis("BodyAcc"), grepthis("GravityAcc")), ncol = nrow(y))
dt$featAcceleration <- factor(x %*% y, labels = c(NA, "Body", "Gravity"))
x <- matrix(c(grepthis("mean()"), grepthis("std()")), ncol = nrow(y))
dt$featVariable <- factor(x %*% y, labels = c("Mean", "SD"))
## Features with 1 category
dt$featJerk <- factor(grepthis("Jerk"), labels = c(NA, "Jerk"))
dt$featMagnitude <- factor(grepthis("Mag"), labels = c(NA, "Magnitude"))
## Features with 3 categories
n <- 3
y <- matrix(seq(1, n), nrow = n)
x <- matrix(c(grepthis("-X"), grepthis("-Y"), grepthis("-Z")), ncol = nrow(y))
dt$featAxis <- factor(x %*% y, labels = c(NA, "X", "Y", "Z"))
#  create the tidy data set
setkey(dt, subject, activity, featDomain, featAcceleration, featInstrument,
featJerk, featMagnitude, featVariable, featAxis)
dtTidy <- dt[, list(count = .N, average = mean(value)), by = key(dt)]
knit("makeCodebook.Rmd", output = "codebook.md", encoding = "ISO8859-1", quiet = TRUE)
#load libraries
library("data.table")
library("reshape2")
library("knitr")
#set the actualPath Variable to work with
actualPath <- getwd()
actualPath
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
f <- "Dataset.zip"
if (!file.exists(actualPath)) {
dir.create(actualPath)
}
#download.file(url, file.path(actualPath, f)) and set time. (in my case: "2014-11-22 17:56:59 CET")
#timeDownloaded <- Sys.time()
timeDownloaded
dataPath <- file.path(actualPath, "UCI HAR Dataset")
list.files(dataPath, recursive = TRUE)
#read files
subjectTrain <- fread(file.path(dataPath, "train", "subject_train.txt"))
subjectTest <- fread(file.path(dataPath, "test", "subject_test.txt"))
yTrain <- fread(file.path(dataPath, "train", "Y_train.txt"))
yTest <- fread(file.path(dataPath, "test", "Y_test.txt"))
fileToDataTable <- function(f) {
df <- read.table(f)
dt <- data.table(df)
}
xTrain <- fileToDataTable(file.path(pathIn, "train", "X_train.txt"))
xTest <- fileToDataTable(file.path(pathIn, "test", "X_test.txt"))
#merge Files
dtSubject <- rbind(subjectTrain, subjectTest)
setnames(dtSubject, "V1", "subject")
dtActivity <- rbind(yTrain, yTest)
setnames(dtActivity, "V1", "activityNum")
dt <- rbind(xTrain, xTest)
dtSubject <- cbind(dtSubject, dtActivity)
dt <- cbind(dtSubject, dt)
setkey(dt, subject, activityNum)
dtFeatures <- fread(file.path(dataPath, "features.txt"))
setnames(dtFeatures, names(dtFeatures), c("featureNum", "featureName"))
dtFeatures <- dtFeatures[grepl("mean\\(\\)|std\\(\\)", featureName)]
dtFeatures$featureCode <- dtFeatures[, paste0("V", featureNum)]
#subsetting
select <- c(key(dt), dtFeatures$featureCode)
dt <- dt[, select, with = FALSE]
#get activity names
activityNames <- fread(file.path(dataPath, "activity_labels.txt"))
setnames(activityNames, names(activityNames), c("activityNum", "activityName"))
#merge lables and data and set key
dt <- merge(dt, activityNames, by = "activityNum", all.x = TRUE)
setkey(dt, subject, activityNum, activityName)
dt <- data.table(melt(dt, key(dt), variable.name = "featureCode"))
dt <- merge(dt, dtFeatures[, list(featureNum, featureCode, featureName)], by = "featureCode", all.x = TRUE)
dt$activity <- factor(dt$activityName)
dt$feature <- factor(dt$featureName)
grepthis <- function(regex) {
grepl(regex, dt$feature)
}
## Features with 2 categories
n <- 2
y <- matrix(seq(1, n), nrow = n)
x <- matrix(c(grepthis("^t"), grepthis("^f")), ncol = nrow(y))
dt$featDomain <- factor(x %*% y, labels = c("Time", "Freq"))
x <- matrix(c(grepthis("Acc"), grepthis("Gyro")), ncol = nrow(y))
dt$featInstrument <- factor(x %*% y, labels = c("Accelerometer", "Gyroscope"))
x <- matrix(c(grepthis("BodyAcc"), grepthis("GravityAcc")), ncol = nrow(y))
dt$featAcceleration <- factor(x %*% y, labels = c(NA, "Body", "Gravity"))
x <- matrix(c(grepthis("mean()"), grepthis("std()")), ncol = nrow(y))
dt$featVariable <- factor(x %*% y, labels = c("Mean", "SD"))
## Features with 1 category
dt$featJerk <- factor(grepthis("Jerk"), labels = c(NA, "Jerk"))
dt$featMagnitude <- factor(grepthis("Mag"), labels = c(NA, "Magnitude"))
## Features with 3 categories
n <- 3
y <- matrix(seq(1, n), nrow = n)
x <- matrix(c(grepthis("-X"), grepthis("-Y"), grepthis("-Z")), ncol = nrow(y))
dt$featAxis <- factor(x %*% y, labels = c(NA, "X", "Y", "Z"))
#  create the tidy data set
setkey(dt, subject, activity, featDomain, featAcceleration, featInstrument,
featJerk, featMagnitude, featVariable, featAxis)
dtTidy <- dt[, list(count = .N, average = mean(value)), by = key(dt)]
knit("makeCodebook.Rmd", output = "codebook.md", encoding = "ISO8859-1", quiet = TRUE)
head(dtTidy)
dtTidy
f <- file.path(actualPath, "TidyData.txt")
write.table(dtTidy, f, quote=FALSE, sep="\t", row.names=FALSE)
library(markdown)
knit("makeCodebook.Rmd", output = "codebook.md", encoding = "ISO8859-1", quiet = TRUE)
knit("run_analysis.Rmd", encoding="ISO8859-1")
